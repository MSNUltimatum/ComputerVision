{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from collections import defaultdict\n",
    "from typing import Tuple, List, NoReturn, DefaultDict, Set, Dict\n",
    "\n",
    "import uuid\n",
    "import faiss\n",
    "import imagehash\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from faiss import IndexBinaryFlat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "class ImageCompactor:\n",
    "    def __init__(self, hash_size: int, image_distance_threshold: int):\n",
    "        self._hash_size: int = hash_size\n",
    "        self._distance_threshold: int = image_distance_threshold\n",
    "        self._index: IndexBinaryFlat = self._load_index()\n",
    "\n",
    "    def compact_images(self, path_to_folder: str) -> NoReturn:\n",
    "        photos_names: List[str] = list(map(lambda x: os.path.join(path_to_folder, x), os.listdir(path_to_folder)))\n",
    "        hashes: List[np.ndarray] = self._fill_index(photos_names)\n",
    "        buckets: DefaultDict[int, Set[str]] = self._select_sets(hashes, photos_names)\n",
    "        self._perform_compaction(buckets, path_to_folder)\n",
    "\n",
    "    def _fill_index(self, photo_names: List[str]) -> List[np.ndarray]:\n",
    "        hashes: List[np.ndarray] = []\n",
    "        for name in photo_names:\n",
    "            file = Image.open(name)\n",
    "            image_hash = self._hash_image(file)\n",
    "            self._index.add(image_hash)\n",
    "            hashes.append(image_hash)\n",
    "        return hashes\n",
    "\n",
    "    def _select_sets(self, hashes: List[np.ndarray], photos_names: List[str]) -> DefaultDict[int, Set[str]]:\n",
    "        used_images: Dict[int, int] = dict()\n",
    "        batches: DefaultDict[int, Set[str]] = defaultdict(lambda: set())\n",
    "        for img_hash in hashes:\n",
    "            s: List[Tuple[int, int]] = self._check_duplicate(img_hash)\n",
    "            current_image_index: int = s[0][0]\n",
    "            bucket_images: List[int] = list(\n",
    "                map(lambda l: l[0], filter(lambda x: x[0] not in used_images and x[1] < self._distance_threshold, s)))\n",
    "            lst = map(lambda l: photos_names[l], bucket_images)\n",
    "            batches[used_images.get(current_image_index, current_image_index)].update(lst)\n",
    "            used_images.update([(k, current_image_index) for k in bucket_images])\n",
    "        return batches\n",
    "\n",
    "    @staticmethod\n",
    "    def _perform_compaction(buckets: DefaultDict[int, Set[str]], path_to_folder: str):\n",
    "        for batch_num, batch in buckets.items():\n",
    "            if len(batch) > 1:\n",
    "                new_folder = os.path.join(path_to_folder, uuid.uuid4().hex)\n",
    "                os.mkdir(new_folder)\n",
    "                for file_path in batch:\n",
    "                    file_name = file_path.rsplit('/')[-1]\n",
    "                    shutil.move(file_path, os.path.join(new_folder, file_name))\n",
    "\n",
    "    def _hash_image(self, im: Image) -> np.ndarray:\n",
    "        im_hash: imagehash.ImageHash = imagehash.average_hash(im, hash_size=self._hash_size)\n",
    "        return np.packbits(np.array(im_hash.hash).reshape(1, self._hash_size ** 2), axis=1)\n",
    "\n",
    "    def _check_duplicate(self, img_hash: np.ndarray) -> List[Tuple[int, int]]:\n",
    "        D, I = self._index.search(img_hash, self._distance_threshold)\n",
    "        return list(zip(I[0], D[0]))\n",
    "\n",
    "    def _load_index(self, filename: str = 'faiss_index') -> IndexBinaryFlat:\n",
    "        d: int = self._hash_size ** 2\n",
    "        try:\n",
    "            return faiss.read_index_binary(f'{filename}_{d}')\n",
    "        except RuntimeError:\n",
    "            return faiss.IndexBinaryFlat(d)\n",
    "\n",
    "    def save_index(self, filename: str = 'faiss_index') -> None:\n",
    "        d: int = self._hash_size ** 2\n",
    "        faiss.write_index_binary(self._index, f'{filename}_{d}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "compactor: ImageCompactor = ImageCompactor(hash_size=16, image_distance_threshold=65)\n",
    "compactor.compact_images(\"images/AlgorithmTest/\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}